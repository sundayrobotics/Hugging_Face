{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ix502iv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk #natural language toolkit -> python\n",
    "import argparse\n",
    "import librosa #audio lib\n",
    "import torch #framework\n",
    "import soundfile as sf\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer #, AutoTokenizer,Wav2Vec2CTCTokenizer\n",
    "\n",
    "#access_token = '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' #hugging face\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav2vec2_960h_model():\n",
    "  \"\"\"\n",
    "  returns the tokenizer and the model from pretrained tokenizer models\n",
    "  \"\"\"\n",
    "  tokenizer = Wav2Vec2Tokenizer.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "                                                #,use_auth_token=access_token)\n",
    "  model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "                                         #,use_auth_token=access_token)\n",
    "  return tokenizer, model\n",
    "\n",
    "def correct_uppercase_sentence(input_text):\n",
    "  \"\"\"\n",
    "  returns the correct sentence\n",
    "  \"\"\"\n",
    "  sentences = nltk.sent_tokenize(input_text)\n",
    "  return(' '.join([s.replace(s[0],s[0].capitalize(),1) for s in sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr_transcription(tokenizer, model, input_file):\n",
    "  \"\"\"\n",
    "  Returns the transcript of the input auio recording\n",
    "  output: transcribed text\n",
    "  input: hugglingface tokenizer, model, wav file\n",
    "  \"\"\"\n",
    "\n",
    "  #read the file\n",
    "  speech, samplerate = sf.read(input_file)\n",
    "  #make it 1-dimentional\n",
    "  if len(speech.shape)>1:\n",
    "    speech = speech[:,0] + speech[:,1]\n",
    "  #resample to 16kHz\n",
    "  if samplerate != 16000:\n",
    "    speech = librosa.resample(speech, samplerate, 16000)\n",
    "  #tokenize\n",
    "  input_values = tokenizer(speech, return_tensors='pt').input_values\n",
    "  #take logits\n",
    "  logits = model(input_values).logits\n",
    "  #take argmax( find most probable word id)\n",
    "  predicted_ids = torch.argmax(logits, dim=-1)\n",
    "  #get the word from the predicted words ids\n",
    "  transcription = tokenizer.decode(predicted_ids[0])\n",
    "  #output all in uppercase\n",
    "  transcription = correct_uppercase_sentence(transcription.lower())\n",
    "  return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "wav_input = \"harvard.wav\"\n",
    "tokenizer, model = load_wav2vec2_960h_model()\n",
    "text = asr_transcription(tokenizer, model, wav_input)\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc128987b80414afb03073ef0ac1a5f16932121e6908c8d5ab86fd86be48a1ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
